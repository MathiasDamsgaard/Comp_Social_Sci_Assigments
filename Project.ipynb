{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Tuple, Union, Optional\n",
    "# Modules\n",
    "import requests\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import xmlrpc.client as xc\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set client to the PyPI XML-RPC server\n",
    "client = xc.ServerProxy('http://pypi.python.org/pypi')\n",
    "\n",
    "# Get a list of all the packages\n",
    "pypi_packages = client.list_packages()\n",
    "\n",
    "# Save the list of packages\n",
    "with open(\"data/packages.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pypi_packages, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def get_github_link(packages: list) -> list:\n",
    "    \"\"\"\n",
    "    Function that takes a list of python packages and returns a list of tuples with the package name, the link to the PyPI page and the link to the GitHub page.\n",
    "    \n",
    "    list_of_packages: list\n",
    "        List of python packages to search for.\n",
    "        \n",
    "    return: list\n",
    "        List of tuples with the package name, the link to the PyPI page and the link to the GitHub page.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_links = []\n",
    "    for i, package in enumerate(packages):\n",
    "        # The link to the python package\n",
    "        LINK = f\"https://pypi.org/project/{package}/\"\n",
    "        \n",
    "        # Get the HTML content of the page\n",
    "        r = requests.get(LINK)\n",
    "        \n",
    "        # If the request was not successful, alert the user\n",
    "        if r.status_code != 200:\n",
    "            print(f\"Request failed for {package, i}: {r.status_code}\")\n",
    "            continue\n",
    "        \n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(r.content)\n",
    "        \n",
    "        # Get sidebar with links\n",
    "        sidebar = soup.find(\"div\", {\"class\": \"vertical-tabs__tabs\"})\n",
    "        \n",
    "        # Get all the links in the sidebar\n",
    "        references = [link.get(\"href\") for link in sidebar.find_all(\"a\")]\n",
    "        \n",
    "        # Join into one string to regex in\n",
    "        reference_text = \" \".join([reference for reference in references if reference is not None])\n",
    "        \n",
    "        # Find the first link that contains the word \"github.com\"\n",
    "        github_links = []\n",
    "        for link in re.finditer(r\"github.com(/\\w*|/\\W|[-]\\w*|[-]\\W*)*\", reference_text):\n",
    "            if link.group() != \"github.com/\" and link.group() != \"github.com\":\n",
    "                github_links.append(link.group())\n",
    "        \n",
    "        # If there are no links, append None\n",
    "        if len(github_links) == 0:\n",
    "            github_link = None\n",
    "        \n",
    "        # If there's several take the shortest and alert the user\n",
    "        elif len(github_links) > 1:\n",
    "            print(f\"Several GitHub links found for {package, i}: {github_links}\")\n",
    "            github_link = min(github_links, key=len)\n",
    "        \n",
    "        # If there is just one link, take that out of the list\n",
    "        elif len(github_links) == 1:\n",
    "            github_link = github_links[0]\n",
    "        \n",
    "        # Else alert the user no githublink is found\n",
    "        else:\n",
    "            print(f\"No GitHub link found for {package, i}\")\n",
    "            github_link = None\n",
    "        \n",
    "        # Append the triplet to the list\n",
    "        all_links.append((package, LINK, github_link))\n",
    "    \n",
    "    return all_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Load packages\n",
    "with open(\"data/packages.pkl\", \"rb\") as f:\n",
    "    pypi_packages = pickle.load(f)\n",
    "\n",
    "# Run the function with threadpool executor to speed up the process - still takes a loooong time so be aware\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    all_links = list(tqdm(executor.map(get_github_link, [pypi_packages]), total=len(pypi_packages)))\n",
    "\n",
    "# Save the list to a json file\n",
    "with open(\"data/all_links_github.json\", \"w\") as f:\n",
    "    json.dump(all_links, f)\n",
    "\n",
    "# Clean the list of None links\n",
    "all_links_c = [(p, l, g) for p, l, g in all_links if g is not None]\n",
    "\n",
    "with open(\"data/all_links_github_c.json\", \"w\") as f:\n",
    "    json.dump(all_links_c, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of packages on pypi: 528577\n",
      "Number of packages to successfully access the webpage: 512780\n",
      "Number of packages to successfully get the github link from: 344841\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/packages.pkl\", \"rb\") as f:\n",
    "    pypi_packages = pickle.load(f)\n",
    "print(\"Number of packages on pypi:\", len(pypi_packages))\n",
    "\n",
    "with open('data/all_links_github.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "print(\"Number of packages to successfully access the webpage:\", len(data))\n",
    "\n",
    "with open('data/all_links_github_c.json', 'r') as f:\n",
    "    data_clean = json.load(f)\n",
    "print(\"Number of packages to successfully get the github link from:\", len(data_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'numpy': {'package': 'numpy', 'link': 'https://pypi.org/project/numpy/', 'github_link': 'github.com/numpy/numpy', 'readme_text': ['h1', 'aligncenter', 'img', 'src', 'powered', 'by', 'numfocus', 'pypi', 'downloads', 'conda', 'downloads', 'stack', 'overflow', 'nature', 'paper', 'openssf', 'scorecard', 'numpy', 'is', 'the', 'fundamental', 'package', 'for', 'scientific', 'computing', 'with', 'python', '-', 'website', '-', 'documentation', '-', 'mailing', 'list', '-', 'source', 'code', '-', 'contributing', '-', 'bug', 'reports', '-', 'report', 'a', 'security', 'vulnerability', 'it', 'provides', '-', 'a', 'powerful', 'n-dimensional', 'array', 'object', '-', 'sophisticated', 'broadcasting', 'functions', '-', 'tools', 'for', 'integrating', '-', 'useful', 'linear', 'algebra', 'fourier', 'transform', 'and', 'random', 'number', 'capabilities', 'testing', 'numpy', 'requires', 'pytest', 'and', 'hypothesis', 'tests', 'can', 'then', 'be', 'run', 'after', 'installation', 'with', 'python', '-c', 'import', 'numpy', 'sys', 'sysexitnumpytest', 'is', 'false', 'code', 'of', 'conduct', '----------------------', 'numpy', 'is', 'a', 'community-driven', 'open', 'source', 'project', 'developed', 'by', 'a', 'diverse', 'group', 'of', 'contributors', 'commitment', 'to', 'creating', 'an', 'open', 'inclusive', 'and', 'positive', 'community', 'please', 'read', 'the', 'numpy', 'code', 'of', 'conduct', 'with', 'others', 'in', 'a', 'way', 'that', 'makes', 'our', 'community', 'thrive', 'call', 'for', 'contributions', '----------------------', 'the', 'numpy', 'project', 'welcomes', 'your', 'expertise', 'and', 'enthusiasm', 'small', 'improvements', 'or', 'fixes', 'are', 'always', 'appreciated', 'if', 'you', 'are', 'considering', 'larger', 'contributions', 'to', 'the', 'source', 'code', 'please', 'contact', 'us', 'through', 'the', 'mailing', 'list', 'writing', 'code', 'isnt', 'the', 'only', 'way', 'to', 'contribute', 'to', 'numpy', 'you', 'can', 'also', '-', 'review', 'pull', 'requests', '-', 'help', 'us', 'stay', 'on', 'top', 'of', 'new', 'and', 'old', 'issues', '-', 'develop', 'tutorials', 'presentations', 'and', 'other', 'educational', 'materials', '-', 'maintain', 'and', 'improve', 'our', 'website', '-', 'develop', 'graphic', 'design', 'for', 'our', 'brand', 'assets', 'and', 'promotional', 'materials', '-', 'translate', 'website', 'content', '-', 'help', 'with', 'outreach', 'and', 'onboard', 'new', 'contributors', '-', 'write', 'grant', 'proposals', 'and', 'help', 'with', 'other', 'fundraising', 'efforts', 'for', 'more', 'information', 'about', 'the', 'ways', 'you', 'can', 'contribute', 'to', 'numpy', 'visit', 'our', 'website', 'if', 'youre', 'unsure', 'where', 'to', 'start', 'or', 'how', 'your', 'skills', 'fit', 'in', 'reach', 'out', 'you', 'can', 'ask', 'on', 'the', 'mailing', 'list', 'or', 'here', 'on', 'github', 'by', 'opening', 'a', 'new', 'issue', 'or', 'leaving', 'a', 'comment', 'on', 'a', 'relevant', 'issue', 'that', 'is', 'already', 'open', 'our', 'preferred', 'channels', 'of', 'communication', 'are', 'all', 'public', 'but', 'if', 'youd', 'like', 'to', 'speak', 'to', 'us', 'in', 'private', 'first', 'contact', 'our', 'community', 'coordinators', 'at', 'numpy-teamgooglegroupscom', 'or', 'on', 'slack', 'write', 'numpy-teamgooglegroupscom', 'for', 'an', 'invitation', 'we', 'also', 'have', 'a', 'biweekly', 'community', 'call', 'details', 'of', 'which', 'are', 'announced', 'on', 'the', 'mailing', 'list', 'you', 'are', 'very', 'welcome', 'to', 'join', 'if', 'you', 'are', 'new', 'to', 'contributing', 'to', 'open', 'source', 'this', 'guide', 'and', 'how', 'to', 'successfully', 'get', 'involved'], 'requirements_text': ['conda-forge', 'python', 'cython', 'compilers', 'openblas', 'nomkl', 'setuptools', 'ninja', 'pkg-config', 'meson-python', 'pip', 'spin', 'ccache', 'pytest', 'pytest-cov', 'pytest-xdist', 'hypothesis', 'typing_extensions', 'mypy', 'sphinx', 'sphinx-design', 'numpydoc', 'ipython', 'scipy', 'pandas', 'matplotlib', 'pydata-sphinx-theme', 'doxygen', 'breathe', 'pycodestyle', 'gitpython', 'cffi', 'pytz']}}\n"
     ]
    }
   ],
   "source": [
    "# For each package go to the GitHub page and get the readme.text if theres a README.md\n",
    "def get_readme_text(github_link: str) -> list:\n",
    "    \"\"\"\n",
    "    Function that takes a GitHub link and returns the text of the README.md file.\n",
    "    \n",
    "    github_link: str\n",
    "        Link to the GitHub page.\n",
    "        \n",
    "    return: str\n",
    "        Text of the README.md file.\n",
    "    \"\"\"\n",
    "    # If there's no link, return None\n",
    "    if github_link is None:\n",
    "        return None\n",
    "    \n",
    "    github_link = github_link.replace(\"github.com\", \"https://raw.githubusercontent.com\")\n",
    "    \n",
    "    response = requests.get(f\"{github_link}/main/README.md\")\n",
    "    if response.status_code != 200:\n",
    "        response = requests.get(f\"{github_link}/master/README.md\")\n",
    "        if response.status_code != 200:\n",
    "            response = requests.get(f\"{github_link}/main/REAMDE.rst\")\n",
    "            if response.status_code != 200:\n",
    "                response = requests.get(f\"{github_link}/master/REAMDE.rst\")\n",
    "                if response.status_code != 200:\n",
    "                    response = requests.get(f\"{github_link}/main/README.txt\")\n",
    "                    if response.status_code != 200:\n",
    "                        response = requests.get(f\"{github_link}/master/README.txt\")\n",
    "                        if response.status_code != 200:\n",
    "                            return None\n",
    "    \n",
    "    readme_text = response.text\n",
    "\n",
    "    # Remove links which start with http\n",
    "    readme_text = re.sub(r\"http.*\", \"\", readme_text)\n",
    "    # Remove links to files in the repository which start with / or ./ or ../\n",
    "    readme_text = re.sub(r\"/.*|./.*|../.*\", \"\", readme_text)\n",
    "    # Convert /n to space\n",
    "    readme_text = re.sub(r\"\\n\", \" \", readme_text)\n",
    "    # Make all text lowercase\n",
    "    readme_text = readme_text.lower()\n",
    "    # Only keep Alphanumeric characters and - and _\n",
    "    readme_text = re.sub(r\"[^a-z0-9-_ ]\", \"\", readme_text)\n",
    "    # Remove multiple spaces\n",
    "    readme_text = re.sub(r\" +\", \" \", readme_text)\n",
    "    # Remove empty strings\n",
    "    readme_text = [line for line in readme_text.split(\" \") if line != \"\"]\n",
    "\n",
    "    return readme_text\n",
    "\n",
    "\n",
    "def get_requirements_text(github_link: str) -> list:\n",
    "    \"\"\"\n",
    "    Function that takes a GitHub link and returns the text of the requirements.txt file.\n",
    "    \n",
    "    github_link: str\n",
    "        Link to the GitHub page.\n",
    "        \n",
    "    return: str\n",
    "        Text of the requirements.txt file.\n",
    "    \"\"\"\n",
    "    # If there's no link, return None\n",
    "    if github_link is None:\n",
    "        return None\n",
    "    \n",
    "    github_link = github_link.replace(\"github.com\", \"https://raw.githubusercontent.com\")\n",
    "    \n",
    "    response = requests.get(f\"{github_link}/main/requirements-dev.txt\")\n",
    "\n",
    "    txt_bool = True\n",
    "    pyproject_bool = False\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        response = requests.get(f\"{github_link}/master/requirements-dev.txt\")\n",
    "        if response.status_code != 200:\n",
    "            response = requests.get(f\"{github_link}/main/dev-requirements.txt\")\n",
    "            if response.status_code != 200:\n",
    "                response = requests.get(f\"{github_link}/master/dev-requirements.txt\")\n",
    "                if response.status_code != 200:\n",
    "                    txt_bool = False\n",
    "                    response = requests.get(f\"{github_link}/main/environment.yml\")\n",
    "                    if response.status_code != 200:\n",
    "                        response = requests.get(f\"{github_link}/master/environment.yml\")\n",
    "                        if response.status_code != 200:\n",
    "                            pyproject_bool = True\n",
    "                            response = requests.get(f\"{github_link}/main/pyproject.toml\")\n",
    "                            if response.status_code != 200:\n",
    "                                response = requests.get(f\"{github_link}/master/pyproject.toml\")\n",
    "                                if response.status_code != 200:\n",
    "                                    pyproject_bool = False\n",
    "                                    txt_bool = True\n",
    "                                    response = requests.get(f\"{github_link}/main/requirements.txt\")\n",
    "                                    if response.status_code != 200:\n",
    "                                        response = requests.get(f\"{github_link}/master/requirements.txt\")\n",
    "                                        if response.status_code != 200:\n",
    "                                            response = requests.get(f\"{github_link}/main/requirements.txt\")                                \n",
    "\n",
    "    requirements_text = response.text\n",
    "\n",
    "    # Clean the text using regex\n",
    "    cleaning_reg = r\"=.*|>.*|~.*|\\[.*\\]|;.*|<.*|!.*\"\n",
    "\n",
    "    if txt_bool:\n",
    "        # Example: \n",
    "            # versioneer[toml]\n",
    "            # cython~=3.0.5\n",
    "            # meson[ninja]==1.2.1\n",
    "            # meson-python==0.13.1\n",
    "            # pytest>=7.3.2\n",
    "            # pytest-cov\n",
    "            # pytest-xdist>=2.2.0\n",
    "            # pytest-qt>=4.2.0\n",
    "        # We only want the package name and not the version or extras\n",
    "        requirements_text = re.sub(r\"\\[.*\\]\", \"\", requirements_text)\n",
    "        # Remove comments\n",
    "        requirements_text = re.sub(r\"#.*\", \"\", requirements_text)\n",
    "        # Convert to list\n",
    "        requirements_text = requirements_text.split(\"\\n\")\n",
    "        # Remove empty strings\n",
    "        requirements_text = [requirement for requirement in requirements_text if requirement != \"\"]\n",
    "\n",
    "    elif pyproject_bool:\n",
    "        # Example:\n",
    "            # [project]\n",
    "            # name = \"pydata-sphinx-theme\"\n",
    "            # description = \"Bootstrap-based Sphinx theme from the PyData community\"\n",
    "            # readme = \"README.md\"\n",
    "            # requires-python = \">=3.9\"\n",
    "            # dependencies = [\n",
    "            # \"Babel\",\n",
    "            # \"pygments>=2.7\",\n",
    "            # \"accessible-pygments\",\n",
    "            # \"typing-extensions\"\n",
    "            # ]\n",
    "            # [project.optional-dependencies]\n",
    "            # doc = [\n",
    "            # \"numpydoc\",\n",
    "            # \"linkify-it-py\", # for link shortening\n",
    "            # \"rich\",\n",
    "            # # For examples section\n",
    "            # \"myst-parser\"\n",
    "            # ]\n",
    "\n",
    "        # Remove comments\n",
    "        requirements_text = re.sub(r\"#.*\", \"\", requirements_text)\n",
    "        dependencies = re.findall(r'dependencies = \\[\\n(.*?)\\n\\]', requirements_text, re.DOTALL)\n",
    "        optional_dependencies = re.findall(r'optional-dependencies\\]\\n.*? = \\[\\n(.*?)\\n\\]', requirements_text, re.DOTALL)\n",
    "        if len(dependencies) == 0:\n",
    "            return None\n",
    "        if len(optional_dependencies) == 0:\n",
    "            optional_dependencies = [\"\"]\n",
    "        \n",
    "        dependencies = re.findall(r'\".*\"', dependencies[0])\n",
    "        optional_dependencies = re.findall(r'\".*\"', optional_dependencies[0])\n",
    "        requirements_text = dependencies + optional_dependencies\n",
    "        # Remove double quotes\n",
    "        requirements_text = [requirement[1:-1] for requirement in requirements_text]\n",
    "        # Clean the text using regex\n",
    "        requirements_text = [re.sub(f\"{cleaning_reg}\", \"\", requirement) for requirement in requirements_text]\n",
    "        # Remove empty strings\n",
    "        requirements_text = [requirement for requirement in requirements_text if requirement != \"\"]\n",
    "\n",
    "    else:\n",
    "        # Example:\n",
    "            # name: myenv\n",
    "            # channels:\n",
    "            #   - defaults\n",
    "            # dependencies:\n",
    "            #   - numpy\n",
    "            #   - pandas\n",
    "            #   - pip\n",
    "            #   - pip:\n",
    "            #     - matplotlib\n",
    "        \n",
    "        # Remove comments\n",
    "        requirements_text = re.sub(r\"#.*\", \"\", requirements_text)\n",
    "        # Only get the dependencies which start with '- '\n",
    "        requirements_text = re.findall(r\"- .*\", requirements_text)\n",
    "        # Clean the text using regex\n",
    "        requirements_text = [re.sub(f\"{cleaning_reg}\", \"\", requirement) for requirement in requirements_text]\n",
    "        # Convert to list\n",
    "        requirements_text = [requirement[2:] for requirement in requirements_text]\n",
    "        # Remove empty strings\n",
    "        requirements_text = [requirement for requirement in requirements_text if requirement != \"\"]\n",
    "           \n",
    "    return requirements_text\n",
    "\n",
    "\n",
    "def node_creator(data: Tuple[str, str, str]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Function that takes a list of tuples with the package name, the link to the PyPI page and the link to the GitHub page and returns a dictionary with the package name as the key and the value is a dictionary with the package name, the link to the PyPI page, the link to the GitHub page, the text of the README.md file and the text of the requirements.txt file.\n",
    "    \n",
    "    data: list\n",
    "        List of tuples with the package name, the link to the PyPI page and the link to the GitHub page.\n",
    "        \n",
    "    return: dict\n",
    "        Dictionary with the package name as the key and the value is a dictionary with the package name, the link to the PyPI page, the link to the GitHub page, the text of the README.md file and the text of the requirements.txt file.\n",
    "    \"\"\"\n",
    "    node = {}\n",
    "    \n",
    "    package, link, github_link = data\n",
    "\n",
    "    readme_text = get_readme_text(github_link)\n",
    "    requirements_text = get_requirements_text(github_link)\n",
    "    if requirements_text is None:\n",
    "        return None\n",
    "    node[package] = {\"package\": package, \"link\": link, \"github_link\": github_link, \"readme_text\": readme_text, \"requirements_text\": requirements_text}\n",
    "    \n",
    "    return node\n",
    "\n",
    "# Test the function\n",
    "test_data = (\"numpy\", \"https://pypi.org/project/numpy/\", \"github.com/numpy/numpy\")\n",
    "test_node = node_creator(test_data)\n",
    "print(test_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load clean data\n",
    "with open('data/all_links_github_c.json', 'r') as f:\n",
    "    data_clean = json.load(f)\n",
    "\n",
    "# Run the function with threadpool executor to speed up the process\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    nodes = list(tqdm(executor.map(node_creator, data_clean[220000:]), total=len(data_clean[220000:])))\n",
    "\n",
    "# Save the list to a json file\n",
    "with open(\"data/nodes_mat.json\", \"w\") as f:\n",
    "    json.dump(nodes, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
